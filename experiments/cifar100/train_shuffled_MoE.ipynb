{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "import random\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from models.cifar100.cifar100resnet import CifarResNet\n",
    "from models.cifar100.cifar100expert import CifarExpert\n",
    "from models.cifar100.gating_network import GatingNetwork\n",
    "from models.cifar100.moe import MoE\n",
    "from utils.cifar100_dataset import CIFAR100Dataset, create_subset\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformations_training = torchvision.transforms.Compose([\n",
    "                torchvision.transforms.RandomHorizontalFlip(p=0.5),\n",
    "                torchvision.transforms.RandomCrop(size=32, padding=4),\n",
    "                torchvision.transforms.ToTensor(),\n",
    "                torchvision.transforms.Normalize(mean=[0.507, 0.487, 0.441], std=[0.267, 0.256, 0.276])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "feature_extractor = CifarResNet(name='CIFAR100 Feature Extractor')\n",
    "feature_extractor.load_state_dict(torch.load('./trained_models/baseline_model.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "experts = []\n",
    "for file in os.listdir('./trained_models/shuffled_moe/'):\n",
    "    if 'expert' in file:\n",
    "        classes = []\n",
    "        for cls in list(map(int, re.findall('\\d+', file))):\n",
    "            classes.append(CIFAR100Dataset.CIFAR100_DECODING[cls])\n",
    "        expert = CifarExpert(classes=classes, name=file, feature_extractor=feature_extractor)\n",
    "        experts.append(expert)\n",
    "moe.experts = experts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "60"
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "len(moe.experts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new experts\n",
    "\n",
    "expert_classes = []\n",
    "for i in range(3):\n",
    "    encoded_class_labels = set([i for i in range(100)])\n",
    "    for j in range(10):\n",
    "        classes_encoded = sorted(random.sample(encoded_class_labels, 10))\n",
    "        classes_decoded = []\n",
    "        for cls in classes_encoded:\n",
    "            classes_decoded.append(CIFAR100Dataset.CIFAR100_DECODING[cls])\n",
    "        expert_classes.append((classes_decoded, classes_encoded))\n",
    "        encoded_class_labels = encoded_class_labels - set(classes_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "experts = []\n",
    "for classes in expert_classes:\n",
    "    label_string = ''\n",
    "    for cls in classes[1][:-1]:\n",
    "        label_string += str(cls) + '_'\n",
    "    label_string += str(classes[1][-1])\n",
    "    expert = CifarExpert(classes=classes[0], name='expert_'+ label_string, feature_extractor=feature_extractor)\n",
    "    experts.append(expert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar_data = CIFAR100Dataset(data_folder='../data/cifar100/training', transform=transformations_training)\n",
    "training_data, validation_data = cifar_data.train_test_split([0.8, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "moe = MoE(\n",
    "    experts=experts,\n",
    "    Gate=GatingNetwork,\n",
    "    name='MoE_shuffled_',\n",
    "    feature_extractor=feature_extractor,\n",
    "    data_folder='/home/lb4653/thesis/mixture-of-experts-thesis/data/cifar100/training',\n",
    "    transform=transformations_training\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "--\nTraining of expert_44_14_94_87_19_6_85_63_9_12.pth\nTraining on device: cuda:0\nTraining on 4,023 samples\nValidation on 977 samples\nNumber of parameters: 2,173,710\n\nEpoch 1/10\n----------\ntraining Loss: 0.9734  Top1 Accuracy: 0.6622\nvalidation Loss: 0.6515  Top1 Accuracy: 0.7840\n\nEpoch 2/10\n----------\ntraining Loss: 0.6079  Top1 Accuracy: 0.7852\nvalidation Loss: 0.6331  Top1 Accuracy: 0.7922\n\nEpoch 3/10\n----------\ntraining Loss: 0.5203  Top1 Accuracy: 0.8101\nvalidation Loss: 0.5920  Top1 Accuracy: 0.8045\n\nEpoch 4/10\n----------\ntraining Loss: 0.4667  Top1 Accuracy: 0.8342\nvalidation Loss: 0.6351  Top1 Accuracy: 0.8045\n\nEpoch 5/10\n----------\ntraining Loss: 0.4634  Top1 Accuracy: 0.8417\nvalidation Loss: 0.6767  Top1 Accuracy: 0.7892\n\nEpoch 6/10\n----------\ntraining Loss: 0.3895  Top1 Accuracy: 0.8566\nvalidation Loss: 0.6331  Top1 Accuracy: 0.7953\n\nEpoch 7/10\n----------\ntraining Loss: 0.3719  Top1 Accuracy: 0.8732\nvalidation Loss: 0.6089  Top1 Accuracy: 0.8066\n\nEpoch 8/10\n----------\ntraining Loss: 0.3151  Top1 Accuracy: 0.8914\nvalidation Loss: 0.6342  Top1 Accuracy: 0.8086\n\nEpoch 9/10\n----------\ntraining Loss: 0.3091  Top1 Accuracy: 0.8869\nvalidation Loss: 0.6691  Top1 Accuracy: 0.7963\n\nEpoch 10/10\n----------\ntraining Loss: 0.2674  Top1 Accuracy: 0.9078\nvalidation Loss: 0.7214  Top1 Accuracy: 0.7943\n\nTraining complete in 0m 15s\nBest Top1 Accuracy on validation set: 0.8086\n------------------------------------ Finished Training ------------------------------------ \n \n\nSaved model state at  ./trained_models/shuffled_moe/expert_44_14_94_87_19_6_85_63_9_12.pth.pth\n------------------------------------ Beginning Training ------------------------------------\nTraining of expert_73_10_47_70_59_9_49_38_27_20.pth\nTraining on device: cuda:0\nTraining on 3,962 samples\nValidation on 1,038 samples\nNumber of parameters: 2,173,710\n\nEpoch 1/10\n----------\ntraining Loss: 0.7295  Top1 Accuracy: 0.7403\nvalidation Loss: 0.5810  Top1 Accuracy: 0.8150\n\nEpoch 2/10\n----------\ntraining Loss: 0.4610  Top1 Accuracy: 0.8390\nvalidation Loss: 0.4457  Top1 Accuracy: 0.8304\n\nEpoch 3/10\n----------\ntraining Loss: 0.3837  Top1 Accuracy: 0.8657\nvalidation Loss: 0.4787  Top1 Accuracy: 0.8430\n\nEpoch 4/10\n----------\ntraining Loss: 0.3423  Top1 Accuracy: 0.8753\nvalidation Loss: 0.4382  Top1 Accuracy: 0.8410\n\nEpoch 5/10\n----------\ntraining Loss: 0.3175  Top1 Accuracy: 0.8849\nvalidation Loss: 0.4806  Top1 Accuracy: 0.8266\n\nEpoch 6/10\n----------\ntraining Loss: 0.3097  Top1 Accuracy: 0.8884\nvalidation Loss: 0.4653  Top1 Accuracy: 0.8285\n\nEpoch 7/10\n----------\ntraining Loss: 0.2814  Top1 Accuracy: 0.8995\nvalidation Loss: 0.5778  Top1 Accuracy: 0.8208\n\nEpoch 8/10\n----------\ntraining Loss: 0.2546  Top1 Accuracy: 0.9036\nvalidation Loss: 0.5295  Top1 Accuracy: 0.8382\n\nEpoch 9/10\n----------\ntraining Loss: 0.2155  Top1 Accuracy: 0.9233\nvalidation Loss: 0.4148  Top1 Accuracy: 0.8709\n\nEpoch 10/10\n----------\ntraining Loss: 0.2161  Top1 Accuracy: 0.9225\nvalidation Loss: 0.5448  Top1 Accuracy: 0.8459\n\nTraining complete in 0m 15s\nBest Top1 Accuracy on validation set: 0.8709\n------------------------------------ Finished Training ------------------------------------ \n \n\nSaved model state at  ./trained_models/shuffled_moe/expert_73_10_47_70_59_9_49_38_27_20.pth.pth\n------------------------------------ Beginning Training ------------------------------------\nTraining of expert_5_15_19_37_42_59_81_92_93_96.pth\nTraining on device: cuda:0\nTraining on 3,990 samples\nValidation on 1,010 samples\nNumber of parameters: 2,173,710\n\nEpoch 1/10\n----------\ntraining Loss: 0.9240  Top1 Accuracy: 0.6709\nvalidation Loss: 0.6835  Top1 Accuracy: 0.7584\n\nEpoch 2/10\n----------\ntraining Loss: 0.6027  Top1 Accuracy: 0.7802\nvalidation Loss: 0.6552  Top1 Accuracy: 0.7743\n\nEpoch 3/10\n----------\ntraining Loss: 0.5412  Top1 Accuracy: 0.8085\nvalidation Loss: 0.5625  Top1 Accuracy: 0.8040\n\nEpoch 4/10\n----------\ntraining Loss: 0.4676  Top1 Accuracy: 0.8356\nvalidation Loss: 0.6426  Top1 Accuracy: 0.7762\n\nEpoch 5/10\n----------\ntraining Loss: 0.4380  Top1 Accuracy: 0.8451\nvalidation Loss: 0.6052  Top1 Accuracy: 0.7901\n\nEpoch 6/10\n----------\ntraining Loss: 0.4004  Top1 Accuracy: 0.8561\nvalidation Loss: 0.5963  Top1 Accuracy: 0.7960\n\nEpoch 7/10\n----------\ntraining Loss: 0.3547  Top1 Accuracy: 0.8707\nvalidation Loss: 0.5140  Top1 Accuracy: 0.8208\n\nEpoch 8/10\n----------\ntraining Loss: 0.3777  Top1 Accuracy: 0.8674\nvalidation Loss: 0.5407  Top1 Accuracy: 0.8168\n\nEpoch 9/10\n----------\ntraining Loss: 0.3302  Top1 Accuracy: 0.8762\nvalidation Loss: 0.5706  Top1 Accuracy: 0.8228\n\nEpoch 10/10\n----------\ntraining Loss: 0.2844  Top1 Accuracy: 0.8960\nvalidation Loss: 0.6510  Top1 Accuracy: 0.8109\n\nTraining complete in 0m 15s\nBest Top1 Accuracy on validation set: 0.8228\n------------------------------------ Finished Training ------------------------------------ \n \n\nSaved model state at  ./trained_models/shuffled_moe/expert_5_15_19_37_42_59_81_92_93_96.pth.pth\n------------------------------------ Beginning Training ------------------------------------\nTraining of expert_49_78_76_63_87_22_57_52_8_14.pth\nTraining on device: cuda:0\nTraining on 4,041 samples\nValidation on 959 samples\nNumber of parameters: 2,173,710\n\nEpoch 1/10\n----------\ntraining Loss: 0.7319  Top1 Accuracy: 0.7580\nvalidation Loss: 0.6411  Top1 Accuracy: 0.8071\n\nEpoch 2/10\n----------\ntraining Loss: 0.4316  Top1 Accuracy: 0.8570\nvalidation Loss: 0.5415  Top1 Accuracy: 0.8196\n\nEpoch 3/10\n----------\ntraining Loss: 0.3623  Top1 Accuracy: 0.8735\nvalidation Loss: 0.5204  Top1 Accuracy: 0.8342\n\nEpoch 4/10\n----------\ntraining Loss: 0.3250  Top1 Accuracy: 0.8834\nvalidation Loss: 0.5553  Top1 Accuracy: 0.8269\n\nEpoch 5/10\n----------\ntraining Loss: 0.3009  Top1 Accuracy: 0.8956\nvalidation Loss: 0.5717  Top1 Accuracy: 0.8259\n\nEpoch 6/10\n----------\ntraining Loss: 0.2839  Top1 Accuracy: 0.9003\nvalidation Loss: 0.5668  Top1 Accuracy: 0.8217\n\nEpoch 7/10\n----------\ntraining Loss: 0.2474  Top1 Accuracy: 0.9154\nvalidation Loss: 0.4988  Top1 Accuracy: 0.8519\n\nEpoch 8/10\n----------\ntraining Loss: 0.2342  Top1 Accuracy: 0.9216\nvalidation Loss: 0.5243  Top1 Accuracy: 0.8384\n\nEpoch 9/10\n----------\ntraining Loss: 0.1953  Top1 Accuracy: 0.9327\nvalidation Loss: 0.5806  Top1 Accuracy: 0.8217\n\nEpoch 10/10\n----------\ntraining Loss: 0.1945  Top1 Accuracy: 0.9307\nvalidation Loss: 0.6143  Top1 Accuracy: 0.8144\n\nTraining complete in 0m 15s\nBest Top1 Accuracy on validation set: 0.8519\n------------------------------------ Finished Training ------------------------------------ \n \n\nSaved model state at  ./trained_models/shuffled_moe/expert_49_78_76_63_87_22_57_52_8_14.pth.pth\n------------------------------------ Beginning Training ------------------------------------\nTraining of expert_99_4_51_57_30_32_96_71_97_61.pth\nTraining on device: cuda:0\nTraining on 4,021 samples\nValidation on 979 samples\nNumber of parameters: 2,173,710\n\nEpoch 1/10\n----------\ntraining Loss: 0.8401  Top1 Accuracy: 0.7212\nvalidation Loss: 0.6113  Top1 Accuracy: 0.7957\n\nEpoch 2/10\n----------\ntraining Loss: 0.5294  Top1 Accuracy: 0.8264\nvalidation Loss: 0.5590  Top1 Accuracy: 0.8223\n\nEpoch 3/10\n----------\ntraining Loss: 0.4550  Top1 Accuracy: 0.8461\nvalidation Loss: 0.5533  Top1 Accuracy: 0.8253\n\nEpoch 4/10\n----------\ntraining Loss: 0.3945  Top1 Accuracy: 0.8684\nvalidation Loss: 0.5462  Top1 Accuracy: 0.8294\n\nEpoch 5/10\n----------\ntraining Loss: 0.3543  Top1 Accuracy: 0.8811\nvalidation Loss: 0.5190  Top1 Accuracy: 0.8243\n\nEpoch 6/10\n----------\ntraining Loss: 0.3226  Top1 Accuracy: 0.8883\nvalidation Loss: 0.5465  Top1 Accuracy: 0.8294\n\nEpoch 7/10\n----------\ntraining Loss: 0.2772  Top1 Accuracy: 0.9045\nvalidation Loss: 0.5623  Top1 Accuracy: 0.8335\n\nEpoch 8/10\n----------\ntraining Loss: 0.2860  Top1 Accuracy: 0.9003\nvalidation Loss: 0.6045  Top1 Accuracy: 0.8376\n\nEpoch 9/10\n----------\ntraining Loss: 0.2665  Top1 Accuracy: 0.9052\nvalidation Loss: 0.5268  Top1 Accuracy: 0.8345\n\nEpoch 10/10\n----------\ntraining Loss: 0.2103  Top1 Accuracy: 0.9296\nvalidation Loss: 0.5518  Top1 Accuracy: 0.8335\n\nTraining complete in 0m 15s\nBest Top1 Accuracy on validation set: 0.8376\n------------------------------------ Finished Training ------------------------------------ \n \n\nSaved model state at  ./trained_models/shuffled_moe/expert_99_4_51_57_30_32_96_71_97_61.pth.pth\n------------------------------------ Beginning Training ------------------------------------\nTraining of expert_12_4_51_71_30_88_41_85_46_29.pth\nTraining on device: cuda:0\nTraining on 4,009 samples\nValidation on 991 samples\nNumber of parameters: 2,173,710\n\nEpoch 1/10\n----------\ntraining Loss: 0.8266  Top1 Accuracy: 0.7189\nvalidation Loss: 0.6847  Top1 Accuracy: 0.7841\n\nEpoch 2/10\n----------\ntraining Loss: 0.5531  Top1 Accuracy: 0.8154\nvalidation Loss: 0.5423  Top1 Accuracy: 0.8143\n\nEpoch 3/10\n----------\ntraining Loss: 0.4364  Top1 Accuracy: 0.8553\nvalidation Loss: 0.6051  Top1 Accuracy: 0.8022\n\nEpoch 4/10\n----------\ntraining Loss: 0.4251  Top1 Accuracy: 0.8498\nvalidation Loss: 0.5534  Top1 Accuracy: 0.8254\n\nEpoch 5/10\n----------\ntraining Loss: 0.3895  Top1 Accuracy: 0.8728\nvalidation Loss: 0.5275  Top1 Accuracy: 0.8194\n\nEpoch 6/10\n----------\ntraining Loss: 0.3263  Top1 Accuracy: 0.8927\nvalidation Loss: 0.5797  Top1 Accuracy: 0.8264\n\nEpoch 7/10\n----------\ntraining Loss: 0.3199  Top1 Accuracy: 0.8858\nvalidation Loss: 0.5708  Top1 Accuracy: 0.8204\n\nEpoch 8/10\n----------\ntraining Loss: 0.2791  Top1 Accuracy: 0.9037\nvalidation Loss: 0.5521  Top1 Accuracy: 0.8385\n\nEpoch 9/10\n----------\ntraining Loss: 0.2597  Top1 Accuracy: 0.9092\nvalidation Loss: 0.5436  Top1 Accuracy: 0.8406\n\nEpoch 10/10\n----------\ntraining Loss: 0.2227  Top1 Accuracy: 0.9224\nvalidation Loss: 0.6015  Top1 Accuracy: 0.8224\n\nTraining complete in 0m 15s\nBest Top1 Accuracy on validation set: 0.8406\n------------------------------------ Finished Training ------------------------------------ \n \n\nSaved model state at  ./trained_models/shuffled_moe/expert_12_4_51_71_30_88_41_85_46_29.pth.pth\n------------------------------------ Beginning Training ------------------------------------\nTraining of expert_33_86_53_31_84_67_39_92_56_74.pth\nTraining on device: cuda:0\nTraining on 3,965 samples\nValidation on 1,035 samples\nNumber of parameters: 2,173,710\n\nEpoch 1/10\n----------\ntraining Loss: 0.8113  Top1 Accuracy: 0.7243\nvalidation Loss: 0.4869  Top1 Accuracy: 0.8300\n\nEpoch 2/10\n----------\ntraining Loss: 0.4670  Top1 Accuracy: 0.8393\nvalidation Loss: 0.4595  Top1 Accuracy: 0.8522\n\nEpoch 3/10\n----------\ntraining Loss: 0.3965  Top1 Accuracy: 0.8651\nvalidation Loss: 0.4602  Top1 Accuracy: 0.8464\n\nEpoch 4/10\n----------\ntraining Loss: 0.3411  Top1 Accuracy: 0.8802\nvalidation Loss: 0.4422  Top1 Accuracy: 0.8686\n\nEpoch 5/10\n----------\ntraining Loss: 0.3183  Top1 Accuracy: 0.8855\nvalidation Loss: 0.4496  Top1 Accuracy: 0.8522\n\nEpoch 6/10\n----------\ntraining Loss: 0.2832  Top1 Accuracy: 0.9024\nvalidation Loss: 0.4546  Top1 Accuracy: 0.8551\n\nEpoch 7/10\n----------\ntraining Loss: 0.2842  Top1 Accuracy: 0.9019\nvalidation Loss: 0.5266  Top1 Accuracy: 0.8396\n\nEpoch 8/10\n----------\ntraining Loss: 0.2390  Top1 Accuracy: 0.9117\nvalidation Loss: 0.4682  Top1 Accuracy: 0.8705\n\nEpoch 9/10\n----------\ntraining Loss: 0.1939  Top1 Accuracy: 0.9304\nvalidation Loss: 0.4703  Top1 Accuracy: 0.8570\n\nEpoch 10/10\n----------\ntraining Loss: 0.1814  Top1 Accuracy: 0.9349\nvalidation Loss: 0.4759  Top1 Accuracy: 0.8628\n\nTraining complete in 0m 15s\nBest Top1 Accuracy on validation set: 0.8705\n------------------------------------ Finished Training ------------------------------------ \n \n\nSaved model state at  ./trained_models/shuffled_moe/expert_33_86_53_31_84_67_39_92_56_74.pth.pth\n------------------------------------ Beginning Training ------------------------------------\nTraining of expert_29_34_72_52_25_36_26_73_89_98.pth\nTraining on device: cuda:0\nTraining on 4,011 samples\nValidation on 989 samples\nNumber of parameters: 2,173,710\n\nEpoch 1/10\n----------\ntraining Loss: 0.9548  Top1 Accuracy: 0.6744\nvalidation Loss: 0.7299  Top1 Accuracy: 0.7573\n\nEpoch 2/10\n----------\ntraining Loss: 0.6318  Top1 Accuracy: 0.7754\nvalidation Loss: 0.6600  Top1 Accuracy: 0.7856\n\nEpoch 3/10\n----------\ntraining Loss: 0.5557  Top1 Accuracy: 0.8095\nvalidation Loss: 0.6913  Top1 Accuracy: 0.7786\n\nEpoch 4/10\n----------\ntraining Loss: 0.5231  Top1 Accuracy: 0.8192\nvalidation Loss: 0.6771  Top1 Accuracy: 0.7695\n\nEpoch 5/10\n----------\ntraining Loss: 0.4590  Top1 Accuracy: 0.8335\nvalidation Loss: 0.6663  Top1 Accuracy: 0.7927\n\nEpoch 6/10\n----------\ntraining Loss: 0.4442  Top1 Accuracy: 0.8417\nvalidation Loss: 0.6916  Top1 Accuracy: 0.7877\n\nEpoch 7/10\n----------\ntraining Loss: 0.4005  Top1 Accuracy: 0.8599\nvalidation Loss: 0.6620  Top1 Accuracy: 0.7826\n\nEpoch 8/10\n----------\ntraining Loss: 0.3831  Top1 Accuracy: 0.8689\nvalidation Loss: 0.6755  Top1 Accuracy: 0.7947\n\nEpoch 9/10\n----------\ntraining Loss: 0.3318  Top1 Accuracy: 0.8861\nvalidation Loss: 0.6806  Top1 Accuracy: 0.7907\n\nEpoch 10/10\n----------\ntraining Loss: 0.3022  Top1 Accuracy: 0.8925\nvalidation Loss: 0.7376  Top1 Accuracy: 0.7755\n\nTraining complete in 0m 15s\nBest Top1 Accuracy on validation set: 0.7947\n------------------------------------ Finished Training ------------------------------------ \n \n\nSaved model state at  ./trained_models/shuffled_moe/expert_29_34_72_52_25_36_26_73_89_98.pth.pth\n------------------------------------ Beginning Training ------------------------------------\nTraining of expert_3_6_14_62_63_71_83_86_91_97.pth\nTraining on device: cuda:0\nTraining on 3,989 samples\nValidation on 1,011 samples\nNumber of parameters: 2,173,710\n\nEpoch 1/10\n----------\ntraining Loss: 0.8511  Top1 Accuracy: 0.6979\nvalidation Loss: 0.7191  Top1 Accuracy: 0.7824\n\nEpoch 2/10\n----------\ntraining Loss: 0.5721  Top1 Accuracy: 0.8017\nvalidation Loss: 0.5495  Top1 Accuracy: 0.8140\n\nEpoch 3/10\n----------\ntraining Loss: 0.4472  Top1 Accuracy: 0.8486\nvalidation Loss: 0.5639  Top1 Accuracy: 0.8091\n\nEpoch 4/10\n----------\ntraining Loss: 0.4731  Top1 Accuracy: 0.8295\nvalidation Loss: 0.5898  Top1 Accuracy: 0.8249\n\nEpoch 5/10\n----------\ntraining Loss: 0.3901  Top1 Accuracy: 0.8631\nvalidation Loss: 0.5385  Top1 Accuracy: 0.8398\n\nEpoch 6/10\n----------\ntraining Loss: 0.3654  Top1 Accuracy: 0.8734\nvalidation Loss: 0.5997  Top1 Accuracy: 0.8170\n\nEpoch 7/10\n----------\ntraining Loss: 0.3513  Top1 Accuracy: 0.8747\nvalidation Loss: 0.5848  Top1 Accuracy: 0.8210\n\nEpoch 8/10\n----------\ntraining Loss: 0.3488  Top1 Accuracy: 0.8814\nvalidation Loss: 0.5885  Top1 Accuracy: 0.8220\n\nEpoch 9/10\n----------\ntraining Loss: 0.3348  Top1 Accuracy: 0.8804\nvalidation Loss: 0.5403  Top1 Accuracy: 0.8427\n\nEpoch 10/10\n----------\ntraining Loss: 0.2544  Top1 Accuracy: 0.9055\nvalidation Loss: 0.5615  Top1 Accuracy: 0.8437\n\nTraining complete in 0m 15s\nBest Top1 Accuracy on validation set: 0.8437\n------------------------------------ Finished Training ------------------------------------ \n \n\nSaved model state at  ./trained_models/shuffled_moe/expert_3_6_14_62_63_71_83_86_91_97.pth.pth\n------------------------------------ Beginning Training ------------------------------------\nTraining of expert_8_24_26_36_44_49_55_68_70_88.pth\nTraining on device: cuda:0\nTraining on 3,976 samples\nValidation on 1,024 samples\nNumber of parameters: 2,173,710\n\nEpoch 1/10\n----------\ntraining Loss: 0.8659  Top1 Accuracy: 0.7022\nvalidation Loss: 0.6935  Top1 Accuracy: 0.7686\n\nEpoch 2/10\n----------\ntraining Loss: 0.5935  Top1 Accuracy: 0.7998\nvalidation Loss: 0.6081  Top1 Accuracy: 0.8037\n\nEpoch 3/10\n----------\ntraining Loss: 0.4983  Top1 Accuracy: 0.8252\nvalidation Loss: 0.5811  Top1 Accuracy: 0.8047\n\nEpoch 4/10\n----------\ntraining Loss: 0.4615  Top1 Accuracy: 0.8426\nvalidation Loss: 0.5407  Top1 Accuracy: 0.8291\n\nEpoch 5/10\n----------\ntraining Loss: 0.4179  Top1 Accuracy: 0.8566\nvalidation Loss: 0.5386  Top1 Accuracy: 0.8252\n\nEpoch 6/10\n----------\ntraining Loss: 0.3596  Top1 Accuracy: 0.8742\nvalidation Loss: 0.5437  Top1 Accuracy: 0.8369\n\nEpoch 7/10\n----------\ntraining Loss: 0.3257  Top1 Accuracy: 0.8858\nvalidation Loss: 0.5678  Top1 Accuracy: 0.8223\n\nEpoch 8/10\n----------\ntraining Loss: 0.3161  Top1 Accuracy: 0.8908\nvalidation Loss: 0.6121  Top1 Accuracy: 0.8213\n\nEpoch 9/10\n----------\ntraining Loss: 0.3803  Top1 Accuracy: 0.8664\nvalidation Loss: 0.6028  Top1 Accuracy: 0.8242\n\nEpoch 10/10\n----------\ntraining Loss: 0.3054  Top1 Accuracy: 0.8873\nvalidation Loss: 0.5406  Top1 Accuracy: 0.8359\n\nTraining complete in 0m 15s\nBest Top1 Accuracy on validation set: 0.8369\n------------------------------------ Finished Training ------------------------------------ \n \n\nSaved model state at  ./trained_models/shuffled_moe/expert_8_24_26_36_44_49_55_68_70_88.pth.pth\n------------------------------------ Beginning Training ------------------------------------\nTraining of expert_81_35_21_93_65_44_59_89_69_91.pth\nTraining on device: cuda:0\nTraining on 3,974 samples\nValidation on 1,026 samples\nNumber of parameters: 2,173,710\n\nEpoch 1/10\n----------\ntraining Loss: 0.9390  Top1 Accuracy: 0.6709\nvalidation Loss: 0.8024  Top1 Accuracy: 0.7544\n\nEpoch 2/10\n----------\ntraining Loss: 0.6616  Top1 Accuracy: 0.7723\nvalidation Loss: 0.6011  Top1 Accuracy: 0.7885\n\nEpoch 3/10\n----------\ntraining Loss: 0.5663  Top1 Accuracy: 0.8052\nvalidation Loss: 0.6212  Top1 Accuracy: 0.7963\n\nEpoch 4/10\n----------\ntraining Loss: 0.5456  Top1 Accuracy: 0.8093\nvalidation Loss: 0.6058  Top1 Accuracy: 0.7973\n\nEpoch 5/10\n----------\ntraining Loss: 0.4840  Top1 Accuracy: 0.8317\nvalidation Loss: 0.5485  Top1 Accuracy: 0.8070\n\nEpoch 6/10\n----------\ntraining Loss: 0.4040  Top1 Accuracy: 0.8601\nvalidation Loss: 0.5610  Top1 Accuracy: 0.8226\n\nEpoch 7/10\n----------\ntraining Loss: 0.4545  Top1 Accuracy: 0.8417\nvalidation Loss: 0.5756  Top1 Accuracy: 0.8090\n\nEpoch 8/10\n----------\ntraining Loss: 0.4523  Top1 Accuracy: 0.8407\nvalidation Loss: 0.5667  Top1 Accuracy: 0.8216\n\nEpoch 9/10\n----------\ntraining Loss: 0.3933  Top1 Accuracy: 0.8596\nvalidation Loss: 0.5560  Top1 Accuracy: 0.8255\n\nEpoch 10/10\n----------\ntraining Loss: 0.3747  Top1 Accuracy: 0.8674\nvalidation Loss: 0.5885  Top1 Accuracy: 0.8090\n\nTraining complete in 0m 15s\nBest Top1 Accuracy on validation set: 0.8255\n------------------------------------ Finished Training ------------------------------------ \n \n\nSaved model state at  ./trained_models/shuffled_moe/expert_81_35_21_93_65_44_59_89_69_91.pth.pth\n------------------------------------ Beginning Training ------------------------------------\nTraining of expert_63_52_84_7_91_69_50_66_53_85.pth\nTraining on device: cuda:0\nTraining on 4,021 samples\nValidation on 979 samples\nNumber of parameters: 2,173,710\n\nEpoch 1/10\n----------\ntraining Loss: 0.7707  Top1 Accuracy: 0.7401\nvalidation Loss: 0.6858  Top1 Accuracy: 0.7804\n\nEpoch 2/10\n----------\ntraining Loss: 0.4981  Top1 Accuracy: 0.8286\nvalidation Loss: 0.4990  Top1 Accuracy: 0.8284\n\nEpoch 3/10\n----------\ntraining Loss: 0.4440  Top1 Accuracy: 0.8515\nvalidation Loss: 0.5242  Top1 Accuracy: 0.8274\n\nEpoch 4/10\n----------\ntraining Loss: 0.3628  Top1 Accuracy: 0.8707\nvalidation Loss: 0.4787  Top1 Accuracy: 0.8468\n\nEpoch 5/10\n----------\ntraining Loss: 0.3391  Top1 Accuracy: 0.8771\nvalidation Loss: 0.4638  Top1 Accuracy: 0.8458\n\nEpoch 6/10\n----------\ntraining Loss: 0.2978  Top1 Accuracy: 0.8995\nvalidation Loss: 0.4577  Top1 Accuracy: 0.8560\n\nEpoch 7/10\n----------\ntraining Loss: 0.2657  Top1 Accuracy: 0.9065\nvalidation Loss: 0.4766  Top1 Accuracy: 0.8529\n\nEpoch 8/10\n----------\ntraining Loss: 0.2348  Top1 Accuracy: 0.9167\nvalidation Loss: 0.4301  Top1 Accuracy: 0.8723\n\nEpoch 9/10\n----------\ntraining Loss: 0.2245  Top1 Accuracy: 0.9172\nvalidation Loss: 0.5070  Top1 Accuracy: 0.8539\n\nEpoch 10/10\n----------\ntraining Loss: 0.2163  Top1 Accuracy: 0.9232\nvalidation Loss: 0.5369  Top1 Accuracy: 0.8447\n\nTraining complete in 0m 15s\nBest Top1 Accuracy on validation set: 0.8723\n------------------------------------ Finished Training ------------------------------------ \n \n\nSaved model state at  ./trained_models/shuffled_moe/expert_63_52_84_7_91_69_50_66_53_85.pth.pth\n"
    }
   ],
   "source": [
    "moe.train_experts(save_state_path='./trained_models/shuffled_moe/', num_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Training of MoE_shuffled__gate\nTraining on device: cuda:0\nTraining on 40,000 samples\nValidation on 10,000 samples\nNumber of parameters: 1,555,490\n\nEpoch 1/10\n----------\ntraining Loss: 3.1253  Top1 Accuracy: 0.3848  Top5 Accuracy: 0.6867\nvalidation Loss: 2.8644  Top1 Accuracy: 0.4304  Top5 Accuracy: 0.7130\n\nEpoch 2/10\n----------\ntraining Loss: 2.6221  Top1 Accuracy: 0.4898  Top5 Accuracy: 0.7815\nvalidation Loss: 2.7197  Top1 Accuracy: 0.4541  Top5 Accuracy: 0.7424\n\nEpoch 3/10\n----------\ntraining Loss: 2.4680  Top1 Accuracy: 0.5231  Top5 Accuracy: 0.8067\nvalidation Loss: 2.6460  Top1 Accuracy: 0.4773  Top5 Accuracy: 0.7513\n\nEpoch 4/10\n----------\ntraining Loss: 2.3812  Top1 Accuracy: 0.5400  Top5 Accuracy: 0.8150\nvalidation Loss: 2.6330  Top1 Accuracy: 0.4804  Top5 Accuracy: 0.7539\n\nEpoch 5/10\n----------\ntraining Loss: 2.3192  Top1 Accuracy: 0.5531  Top5 Accuracy: 0.8206\nvalidation Loss: 2.6305  Top1 Accuracy: 0.4780  Top5 Accuracy: 0.7585\n\nEpoch 6/10\n----------\ntraining Loss: 2.2664  Top1 Accuracy: 0.5640  Top5 Accuracy: 0.8246\nvalidation Loss: 2.5826  Top1 Accuracy: 0.4880  Top5 Accuracy: 0.7608\n\nEpoch 7/10\n----------\ntraining Loss: 2.2130  Top1 Accuracy: 0.5759  Top5 Accuracy: 0.8291\nvalidation Loss: 2.5766  Top1 Accuracy: 0.4876  Top5 Accuracy: 0.7679\n\nEpoch 8/10\n----------\ntraining Loss: 2.1873  Top1 Accuracy: 0.5818  Top5 Accuracy: 0.8302\nvalidation Loss: 2.5877  Top1 Accuracy: 0.4861  Top5 Accuracy: 0.7627\n\nEpoch 9/10\n----------\ntraining Loss: 2.1520  Top1 Accuracy: 0.5869  Top5 Accuracy: 0.8312\nvalidation Loss: 2.5939  Top1 Accuracy: 0.4856  Top5 Accuracy: 0.7631\n\nEpoch 10/10\n----------\ntraining Loss: 2.1306  Top1 Accuracy: 0.5906  Top5 Accuracy: 0.8346\nvalidation Loss: 2.5727  Top1 Accuracy: 0.4935  Top5 Accuracy: 0.7648\n\nTraining complete in 9m 16s\nBest Top1 Accuracy on validation set: 0.4935\nSaved model state at  ./trained_models/shuffled_moe/gate.pthMoE_shuffled__gate.pth\n------------------------------------ Finished Training ------------------------------------ \n \n\n"
    }
   ],
   "source": [
    "moe.train_gate(save_state_path='./trained_models/shuffled_moe/gate.pth', num_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "moe.gate.load_state_dict(torch.load('./trained_models/shuffled_moe/gate.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (60) must match the size of tensor b (30) at non-singleton dimension 0",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-7479b3974c07>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmoe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate_decisions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/thesis/mixture-of-experts-thesis/models/cifar100/moe.py\u001b[0m in \u001b[0;36mevaluate_decisions\u001b[0;34m(self, test_data, batch_size, criterion, device)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m                     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m                     \u001b[0mweights_sum\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights_sum\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (60) must match the size of tensor b (30) at non-singleton dimension 0"
     ]
    }
   ],
   "source": [
    "moe.evaluate_decisions()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python36964bitvenvmlvenv43865d4333214dd8b422881fc2c770e1",
   "display_name": "Python 3.6.9 64-bit ('venv_ml': venv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}